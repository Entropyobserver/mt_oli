{
    "os": "Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35",
    "python": "3.9.23",
    "heartbeatAt": "2025-09-28T11:14:21.789807",
    "startedAt": "2025-09-28T11:14:20.696842",
    "docker": null,
    "cuda": null,
    "args": [],
    "state": "running",
    "program": "/mnt/d/J/Desktop/language_technology/course/projects_AI/mt_oil/lora/mt_oli/01_data_scaling_experiment.py",
    "codePath": "01_data_scaling_experiment.py",
    "git": {
        "remote": "https://github.com/Entropyobserver/mt_oli.git",
        "commit": "416fbcbd078d60f35389b7def49c9464a91bbf80"
    },
    "email": "sicper@163.com",
    "root": "/mnt/d/J/Desktop/language_technology/course/projects_AI/mt_oil/lora/mt_oli",
    "host": "LAPTOP-C12I2P93",
    "username": "x",
    "executable": "/home/x/anaconda3/envs/llm_env/bin/python",
    "cpu_count": 12,
    "cpu_count_logical": 24,
    "cpu_freq": {
        "current": 2419.199,
        "min": 0.0,
        "max": 0.0
    },
    "cpu_freq_per_core": [
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2419.199,
            "min": 0.0,
            "max": 0.0
        }
    ],
    "disk": {
        "total": 1006.853931427002,
        "used": 283.7933349609375
    },
    "gpu": "NVIDIA GeForce RTX 4060 Laptop GPU",
    "gpu_count": 1,
    "gpu_devices": [
        {
            "name": "NVIDIA GeForce RTX 4060 Laptop GPU",
            "memory_total": 8585740288
        }
    ],
    "memory": {
        "total": 15.476085662841797
    }
}
